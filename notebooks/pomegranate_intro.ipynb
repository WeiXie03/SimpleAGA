{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following [Pomegranate tutorial](https://pomegranate.readthedocs.io/en/latest/tutorials/B_Model_Tutorial_4_Hidden_Markov_Models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/miniconda3/envs/SAGAconf/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pomegranate, pomegranate.hmm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 3\n",
    "# e.g. 0 = dead/quiescent, 1 = promoter, 2 = other actives\n",
    "states = [0, 1, 2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some sample observation data assuming each state's emission ~ Normal.\n",
    "\n",
    "Although in principle, a separate emission distribution for every state-track pair, just use a multivariate Normal, of <# of tracks> dimensions, per state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Normal(loc: torch.Size([3]), scale: torch.Size([3])),\n",
       " Normal(loc: torch.Size([3]), scale: torch.Size([3])),\n",
       " Normal(loc: torch.Size([3]), scale: torch.Size([3]))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEANS = (0.3, 10.0, 6.0)\n",
    "STDEVS = (0.05, 1.0, 0.5)\n",
    "true_emitters = []\n",
    "for mean, stdev in zip(MEANS, STDEVS):\n",
    "    multivar_mean = torch.full([N_TRACKS], mean)\n",
    "    multivar_stdev = torch.full([N_TRACKS], stdev)\n",
    "    true_emitters.append(torch.distributions.Normal(multivar_mean, multivar_stdev))\n",
    "true_emitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emitter 0:\n",
      "\ttensor([0.3000, 0.3000, 0.3000])\n",
      "\ttensor([0.0500, 0.0500, 0.0500])\n",
      "Emitter 1:\n",
      "\ttensor([10., 10., 10.])\n",
      "\ttensor([1., 1., 1.])\n",
      "Emitter 2:\n",
      "\ttensor([6., 6., 6.])\n",
      "\ttensor([0.5000, 0.5000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "for i, emitter in enumerate(true_emitters):\n",
    "    print(f\"Emitter {i}:\\n\\t{emitter.loc}\\n\\t{emitter.scale}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRUE_START_PROBS = [0.8, 0.1, 0.1]\n",
    "sum(TRUE_START_PROBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_TRANS_PROBS = torch.tensor([\n",
    "    [0.8, 0.1, 0.1],\n",
    "    [0.1, 0.6, 0.3],\n",
    "    [0.3, 0.1, 0.6]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ_LEN = 20\n",
    "gen_seq = np.random.choice(states, size=SEQ_LEN, p=TRUE_START_PROBS)\n",
    "gen_seq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose into column vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.6323],\n",
       "        [6.0483],\n",
       "        [6.0506]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_emitters[2].sample().reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3054,  0.2229,  0.3701],\n",
       "        [ 5.5651,  6.5572,  6.5768],\n",
       "        [ 0.3020,  0.3134,  0.3664],\n",
       "        [ 0.2947,  0.2546,  0.3192],\n",
       "        [ 0.2827,  0.2506,  0.2943],\n",
       "        [10.8162, 10.0738,  8.3960],\n",
       "        [ 0.2998,  0.4067,  0.3256],\n",
       "        [ 0.2796,  0.3195,  0.1884],\n",
       "        [ 0.3502,  0.3037,  0.2364],\n",
       "        [ 9.7514,  9.8514,  9.9586],\n",
       "        [ 0.2800,  0.2423,  0.3913],\n",
       "        [ 9.0129,  9.5638, 10.4782],\n",
       "        [ 0.3264,  0.3136,  0.3524],\n",
       "        [ 0.2602,  0.3004,  0.3156],\n",
       "        [ 0.3349,  0.2948,  0.3594],\n",
       "        [ 6.4302,  5.2614,  5.5897],\n",
       "        [ 0.2737,  0.3666,  0.2928],\n",
       "        [ 0.2977,  0.2984,  0.2823],\n",
       "        [10.8006, 12.2314,  9.4856],\n",
       "        [ 0.2861,  0.3369,  0.3937]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = torch.stack([true_emitters[st_id].sample() for st_id in gen_seq])\n",
    "observations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tutorial 4 - Hidden Markov Models | Pomegranate](https://pomegranate.readthedocs.io/en/latest/tutorials/B_Model_Tutorial_4_Hidden_Markov_Models.html)\n",
    "> Similar to other methods, we can create an HMM with uninitialized distributions. These distributions will be __initialized__ using __k-means clustering__ when provided with data. When using a DenseHMM we can also choose to not pass in __edges__ and have them be initialized to __uniform probabilities__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseHMM(\n",
       "  (start): Silent()\n",
       "  (end): Silent()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_means = torch.full([N_TRACKS], observations.mean().item())\n",
    "init_vars = torch.diag(torch.ones(N_TRACKS))\n",
    "model1 = pomegranate.hmm.DenseHMM([pomegranate.distributions.Normal(init_means, init_vars)] * len(states), verbose=True, max_iter=100)\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: pomegranate's `fit` expects a _sequence_ of observations.\n",
    "\n",
    "[Fitting a continuous multivariate HMM from labeled data](https://github.com/jmschrei/pomegranate/issues/485#issuecomment-416662827)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Improvement: 465.9555969238281, Time: 0.004181s\n",
      "[2] Improvement: 7.62939453125e-06, Time: 0.005155s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DenseHMM(\n",
       "  (start): Silent()\n",
       "  (end): Silent()\n",
       "  (distributions): ModuleList(\n",
       "    (0): Normal()\n",
       "    (1): Normal()\n",
       "    (2): Normal()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit([observations])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Observations\n",
    "Apparently, pomegranate can handle missing observations as `None`'s in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[None, None, None],\n",
       " [5.565107345581055, 6.557218551635742, 6.576842784881592],\n",
       " [0.3020317852497101, 0.31342706084251404, 0.36642390489578247],\n",
       " [0.29472455382347107, 0.2545918822288513, 0.31916943192481995],\n",
       " [0.28270891308784485, 0.25064459443092346, 0.2943447232246399],\n",
       " [10.81615924835205, 10.073811531066895, 8.395991325378418],\n",
       " [0.2997661530971527, 0.4067055284976959, 0.32560163736343384],\n",
       " [0.2796158790588379, 0.31951630115509033, 0.18837019801139832],\n",
       " [0.3501664400100708, 0.30370476841926575, 0.2363787293434143],\n",
       " [9.751447677612305, 9.851372718811035, 9.958648681640625],\n",
       " [0.2800060510635376, 0.24227580428123474, 0.39131394028663635],\n",
       " [9.012857437133789, 9.563789367675781, 10.47817611694336],\n",
       " [0.3264276087284088, 0.31359487771987915, 0.3523578941822052],\n",
       " [0.26022782921791077, 0.30037346482276917, 0.3156208395957947],\n",
       " [0.334893137216568, 0.29476144909858704, 0.3594101667404175],\n",
       " [6.430192470550537, 5.261399269104004, 5.589681148529053],\n",
       " [0.2737293243408203, 0.3665965497493744, 0.2928072512149811],\n",
       " [0.29769617319107056, 0.2983541190624237, 0.28233808279037476],\n",
       " [10.800576210021973, 12.23138427734375, 9.485610961914062],\n",
       " [0.28614965081214905, 0.33690959215164185, 0.3936997652053833]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lobservations = observations.tolist()\n",
    "Lobservations[0] = [None] * N_TRACKS\n",
    "Lobservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model1\u001b[39m.\u001b[39;49mfit([Lobservations])\n",
      "File \u001b[0;32m~/miniconda3/envs/SAGAconf/lib/python3.9/site-packages/pomegranate/hmm/_base.py:582\u001b[0m, in \u001b[0;36m_BaseHMM.fit\u001b[0;34m(self, X, sample_weight, priors)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, priors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    521\u001b[0m \u001b[39m\t\u001b[39m\u001b[39m\"\"\"Fit the model to sequences with optional weights and priors.\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \n\u001b[1;32m    523\u001b[0m \u001b[39m\tThis method implements the core of the learning process. For hidden\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[39m\tself\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \u001b[39m\t\"\"\"\u001b[39;00m\n\u001b[0;32m--> 582\u001b[0m \tX, sample_weight, priors \u001b[39m=\u001b[39m partition_sequences(X, \n\u001b[1;32m    583\u001b[0m \t\tsample_weight\u001b[39m=\u001b[39;49msample_weight, priors\u001b[39m=\u001b[39;49mpriors)\n\u001b[1;32m    585\u001b[0m \t\u001b[39m# Initialize by concatenating across sequences\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \t\u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialized:\n",
      "File \u001b[0;32m~/miniconda3/envs/SAGAconf/lib/python3.9/site-packages/pomegranate/_utils.py:418\u001b[0m, in \u001b[0;36mpartition_sequences\u001b[0;34m(X, sample_weight, priors)\u001b[0m\n\u001b[1;32m    415\u001b[0m \t\u001b[39mpass\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m# Otherwise, cast all elements in the list as a tensor\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m X \u001b[39m=\u001b[39m [_cast_as_tensor(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X]\n\u001b[1;32m    420\u001b[0m \u001b[39m# If a list of 3D tensors has been passed in, return it\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/SAGAconf/lib/python3.9/site-packages/pomegranate/_utils.py:418\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    415\u001b[0m \t\u001b[39mpass\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m# Otherwise, cast all elements in the list as a tensor\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m X \u001b[39m=\u001b[39m [_cast_as_tensor(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X]\n\u001b[1;32m    420\u001b[0m \u001b[39m# If a list of 3D tensors has been passed in, return it\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/SAGAconf/lib/python3.9/site-packages/pomegranate/_utils.py:54\u001b[0m, in \u001b[0;36m_cast_as_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, \u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, numpy\u001b[39m.\u001b[39mndarray)):\n\u001b[1;32m     53\u001b[0m \t\u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m \t\t\u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mtensor(value)\n\u001b[1;32m     55\u001b[0m \t\u001b[39melse\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m \t\t\u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(value, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of NoneType"
     ]
    }
   ],
   "source": [
    "model1.fit([Lobservations])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
