## bigWig Parsing
Ok, __action plan__:
- Right now, using pyBigWig module, provides nice `bigWigFile` class. _Stop writing ten functions that each have to be passed_...
	- `bin_size`
	- `parallel` (or not)
- ^ Just extend or mix in `bigWigFile` class into a `bigWigsBinner` class that handles all tracks for __one__ experiment.
	- 

Each chromosome within each track a _separate_ NumPy array?
No, just separate metadata, data:
- 2D list (cut chrom name keys) --> NumPy array
- dictionary/table of final `{chrom: (start, end)}` genome position ranges

# May 30, 2023
No, actually:
- pomegranate __1.0.0__ <-- PyTorch backend => direct convert to __Tensor__
1. init empty Tensor and empty DataFrame
	- sizes:
		- Tensor: ($|genome|/res$, # tracks)
		- DataFrame: (# assays, 3) <-- rows are (assay name, start pos, end pos)
1. fill in chromosome by chromosome
	- can directly pass a tensor into `bigWigFile.stats()`, directly outputs a tensor
2. save each chromosome with name directly to an `out` bigWig file with `bigWigFile.addEntries()`

# May 31, 2023
Alright, final call:
- Yes, Mehdi right, should save as __DataFrame__, will need the flexibility
	- âœ³ _nice_ __slicing ðŸ”ª, indexing__
- Also, _man_, _gotta_ get dat parallel, u know?
So,
1. parallel bigWig --> torch Tensors, CSV of {assay : saved Tensor filename} in C++
	- `save()` in [libbigwig](https://github.com/dpryan79/libBigWig/tree/master)
	- libtorch: [`torch::save()`](https://pytorch.org/cppdocs/api/function_namespacetorch_1a5775d727d867870953200dd89fd3dbb9.html#exhale-function-namespacetorch-1a5775d727d867870953200dd89fd3dbb9)
	- C++ CSV library with writing: [Rapidcsv](https://github.com/d99kris/rapidcsv)
2. 

# June 2, 2023
Hm, um, you know... got new input from the meeting ðŸ‘€
- If `multiprocessing` can't pickle, just launch multiple instances of scripts
	- Then each bin a different chromosome, all chromosomes of all bigWigs in parallel
	- Each write to different NumPy file, merge at end? <-- Then just all disk I/O